{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7LVIOa8l533",
    "outputId": "625ad6ef-2143-4385-9dbb-c83673e5b358"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras import regularizers\n",
    "from scipy.stats import ks_2samp\n",
    "# load data\n",
    "data = pd.read_csv(\"/content/drive/MyDrive/creditcard.csv\")\n",
    "X = data.drop('Class', axis=1).values\n",
    "y = data['Class'].values\n",
    "print(X,y)\n",
    "# plot the class distribution\n",
    "pd.value_counts(data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oB242bgil539"
   },
   "source": [
    "# Distribution of credit card transactions over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "FipPlhvul539",
    "outputId": "c36585ea-0612-411a-c939-433e6e134a35"
   },
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12, 6))\n",
    "\n",
    "bins = 100\n",
    "\n",
    "# Plotting for Fraud transactions\n",
    "ax1.hist(data.Time[data.Class == 1], bins=bins, color='red', alpha=0.7)\n",
    "ax1.set_title('Fraud', fontsize=14)\n",
    "ax1.set_ylabel('Number of Transactions', fontsize=12)\n",
    "ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plotting for Normal transactions\n",
    "ax2.hist(data.Time[data.Class == 0], bins=bins, color='blue', alpha=0.7)\n",
    "ax2.set_title('Normal', fontsize=14)\n",
    "ax2.set_xlabel('Time (in Seconds)', fontsize=12)\n",
    "ax2.set_ylabel('Number of Transactions', fontsize=12)\n",
    "ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Remove top and right spines\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "9Z54LGCyl53_",
    "outputId": "85ac6d74-b8c6-460d-e5fc-54c0f6348900"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([data[data[\"Class\"]==1][\"Amount\"], data[data[\"Class\"]==0][\"Amount\"]],\n",
    "            labels=['Fraud', 'Normal'])\n",
    "\n",
    "plt.title('Transaction Amounts: Fraud vs Normal')\n",
    "plt.ylabel('Amount')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HQ23fzdl54B"
   },
   "source": [
    "# Data Preparation\n",
    "- Split data into training, validation, and test sets (60/20/20).\n",
    "- Use stratified sampling to maintain the class distribution in each split.\n",
    "- Scale the training, validation, and test sets to a mean of zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08LFvrInl54B"
   },
   "outputs": [],
   "source": [
    "# split data into train, validation, and test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "\n",
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oLE0lLsl54C"
   },
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-sKXEbyl54D",
    "outputId": "e8e29f26-a2b5-4f45-f42c-346a641581ac"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        # Adjusted number of neurons\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(X.shape[-1],),\n",
    "                              kernel_regularizer=regularizers.l2(0.001)),  # L2 regularization\n",
    "        tf.keras.layers.Dropout(0.2),  # Adjusted dropout rate\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\",\n",
    "                              kernel_regularizer=regularizers.l2(0.001)),  # L2 regularization\n",
    "        tf.keras.layers.Dropout(0.2),  # Adjusted dropout rate\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmORqOnpl54G"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15vxq9BXl54H"
   },
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    tf.keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    tf.keras.metrics.TruePositives(name=\"tp\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR7frO7il54I"
   },
   "source": [
    "# Model training\n",
    "- Use the Adam optimizer with a learning rate of 0.0001.\n",
    "- Utilize binary cross-entropy as the loss function.\n",
    "- Set up an early stopping callback that monitors the validation loss for minimization.\n",
    "- Specify a patience of 5 epochs before stopping training if the validation loss does not improve.\n",
    "- Set class weights such that class 0 has a weight of 1, and class 1 has a weight of 5, giving more importance to the minority class.\n",
    "- Train for a maximum of 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FhC_py-l54I",
    "outputId": "93b5971a-aed6-4309-8e23-40a1fb4230ef"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics = metrics)\n",
    "\n",
    "# configure early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# calculate class weights\n",
    "neg, pos = np.bincount(y_train)\n",
    "total = neg + pos\n",
    "class_weight = {0: 1, 1: 5}\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, callbacks=[es], class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YB9w7b6nl54J"
   },
   "source": [
    "# Model Evaluation and Loss Visualization\n",
    "- Use the trained model to make predictions on the test dataset.\n",
    "- Calculate precision, recall, and F1 score as evaluation metrics for the model's performance on the test data.\n",
    "- Visualize the training and validation loss over the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 692
    },
    "id": "4BD6DQ5Yl54K",
    "outputId": "c67056ca-559d-44b5-83a4-b03f11fe7a0b"
   },
   "outputs": [],
   "source": [
    "# predict test data\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# score precision, recall, and f1\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Plot only the losses from history\n",
    "losses = history.history['loss']\n",
    "val_losses = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0BBY-zKl54L"
   },
   "source": [
    "- The training Loss decreases sharply at the beginning, which indicates that the model is quickly learning from the training data. As epochs increase, the rate of decrease slows down, suggesting that the model is starting to converge and is learning less from the training data with each epoch.\n",
    "- The validation Loss decreases along with the training loss, but it starts to plateau toward the end. The fact that the validation loss levels off but does not increase indicates that the model is not overfitting.\n",
    "- The early stopping after 30 epochs suggests that the model reached an optimal state in terms of generalization before performance on the validation set could deteriorate."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
